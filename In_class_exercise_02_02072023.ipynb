{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devendarreddybathini/Devendarreddy_INFO5731_spring2023/blob/main/In_class_exercise_02_02072023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjB8lkVFS1EL"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O9iUfMpS1EO"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5lnM9Y5S1EO"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vYOPECkS1EP"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "whenever someone wants to buy a product they always search for the information about it.More specifically\n",
        "the information from people who are already using that product is highly trust worthy.Because they give the accurate and genuine review.\n",
        "This helps the new user to create the perception about it. As the technology evolved tremendously we are able to see multiple online \n",
        "selling platforms like flipkart,amazon which has mutiple products on their websites and the reviews given by the utilizers with it.\n",
        "Analyizing these reviews will not just helps the user, it also helps the product owner to understand how their product is \n",
        "perfprming in the market.Things like goodweel,feature those needs improvment and etc.\n",
        "to get this analysis done,we need to fecth the text data provided by consumer as reviews and then do some sentimental or text mining\n",
        "on that data to gain best results.\n",
        "the more data points are the best for any analysis as there won't be any bias invlove in the selection and \n",
        "the minimum datapoints required to do analysis are 1000.\n",
        "\n",
        "firstly, we need to fectch the user where we can find the data related to reviews of the product\n",
        "on online platform (currently i i have taken filpkart as platform and redme_10 as product)\n",
        "then identify the class names of the text in HTML form where we need to fecth the infomration.\n",
        "clean the data with the help of beautifulsuop.\n",
        "save the data into the python data frame.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1I8CL6YS1EQ"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "Vrun0emcS1EQ",
        "outputId": "a53e5009-0bc5-45eb-f995-59a72e65732b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               SummaryView                                             Review\n",
              "0                Fabulous!  Good phone in this price range, battery backup...\n",
              "1                Wonderful  Very nice mobile 🥳😊Performance is very good 😊C...\n",
              "2           Simply awesome  Good phone very nice working and good performa...\n",
              "3     Good quality product  This phone camera is not good but you can use ...\n",
              "4      Best in the market!  Better backup osm ans camere clarity is very g...\n",
              "...                    ...                                                ...\n",
              "1772         Great product                                      GoodREAD MORE\n",
              "1773       Value-for-money                        Nice in this priceREAD MORE\n",
              "1774            Delightful                                      GoodREAD MORE\n",
              "1775        Decent product         Avg Not impressedNot disappointedREAD MORE\n",
              "1776   Best in the market!                         Very good productREAD MORE\n",
              "\n",
              "[1777 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b00e61ff-17f5-401a-9c20-180155c1b666\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SummaryView</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>Good phone in this price range, battery backup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>Very nice mobile 🥳😊Performance is very good 😊C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simply awesome</td>\n",
              "      <td>Good phone very nice working and good performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Good quality product</td>\n",
              "      <td>This phone camera is not good but you can use ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>Better backup osm ans camere clarity is very g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1772</th>\n",
              "      <td>Great product</td>\n",
              "      <td>GoodREAD MORE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1773</th>\n",
              "      <td>Value-for-money</td>\n",
              "      <td>Nice in this priceREAD MORE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1774</th>\n",
              "      <td>Delightful</td>\n",
              "      <td>GoodREAD MORE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1775</th>\n",
              "      <td>Decent product</td>\n",
              "      <td>Avg Not impressedNot disappointedREAD MORE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>Best in the market!</td>\n",
              "      <td>Very good productREAD MORE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1777 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b00e61ff-17f5-401a-9c20-180155c1b666')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b00e61ff-17f5-401a-9c20-180155c1b666 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b00e61ff-17f5-401a-9c20-180155c1b666');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "header = [] # List to store Review headings\n",
        "body = [] # List to store reviews\n",
        "\n",
        "for number in range(300):\n",
        "    link = \"https://www.flipkart.com/redmi-10-midnight-black-64-gb/product-reviews/itmd93641e4ebb47?pid=MOBGC9GYEBH3GZ4E&lid=LSTMOBGC9GYEBH3GZ4ESWAKTT&marketplace=FLIPKART&page=\" + str(number) # Generating link dynamically\n",
        "    page = requests.get(link) # Accessing the webpage\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    main_reviews = soup.find_all(class_='_2-N8zT') # Getting the Review Heading by using the class name\n",
        "    text_reviews = soup.find_all(class_='t-ZTKy') # Getting the full reviews by using the class name\n",
        "\n",
        "    for ele, sub_ele in zip(main_reviews, text_reviews): # Iterating through the list\n",
        "        header.append(ele.text) # Appending to header list\n",
        "        body.append(sub_ele.text) # Appending to body list\n",
        "\n",
        "df = pd.DataFrame(list(zip(header, body)), columns =['SummaryView', 'Review'])  # Creating Dataframe\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0n3zLliS1ER"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5gcM4nQ6a01n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Define the API endpoint\n",
        "url = \"https://api.semanticscholar.org/graph/v1/paper/search?query=information+retrieval&offset=0&limit=100&year=2012-2022&fields=title,year,venue,journal,publicationTypes,authors,abstract\"\n",
        "\n",
        "# Initialize the offset\n",
        "offset = 0\n",
        "\n",
        "# Store the extracted data in a list of dictionaries\n",
        "papers = []\n",
        "\n",
        "# Loop until we have at least 1000 articles\n",
        "while len(papers) < 1000:\n",
        "    # Send a GET request to the API with the current offset\n",
        "    response = requests.get(f\"{url}&offset={offset}\")\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Extract the data from the response\n",
        "        data = response.json()[\"data\"]\n",
        "\n",
        "        # Append the extracted data to the list of dictionaries\n",
        "        for paper in data:\n",
        "            papers.append({\n",
        "                \"Title\": paper.get(\"title\", \"\"),\n",
        "                \"Venue/journal/conference\": paper.get(\"venue\", \"\") or paper.get(\"journal\", \"\"),\n",
        "                \"Year\": paper.get(\"year\", \"\"),\n",
        "                \"Authors\": paper.get(\"authors\", []),\n",
        "                \"Abstract\": paper.get(\"abstract\", \"\")\n",
        "            })\n",
        "\n",
        "        # Increment the offset\n",
        "        offset += 100\n",
        "    else:\n",
        "        # Print the error message and break the loop\n",
        "        print(f\"Error: {response.text}\")\n",
        "        break\n",
        "\n",
        "# Convert the list of dictionaries to a pandas DataFrame\n",
        "df = pd.DataFrame(papers)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPaGS1WmagT9",
        "outputId": "dd8b86f5-083e-420e-e4e2-f1decf9ed07b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Title  \\\n",
            "0    BEIR: A Heterogenous Benchmark for Zero-shot E...   \n",
            "1                                Information Retrieval   \n",
            "2    Pyserini: A Python Toolkit for Reproducible In...   \n",
            "3    COIL: Revisit Exact Lexical Match in Informati...   \n",
            "4    SPLADE v2: Sparse Lexical and Expansion Model ...   \n",
            "..                                                 ...   \n",
            "995  Fuzzy Rough Set Based Technique for User Speci...   \n",
            "996  HINMINE: heterogeneous information network min...   \n",
            "997  Information retrieval in the workplace: A comp...   \n",
            "998  Single-server Multi-user Private Information R...   \n",
            "999  Information retrieval methodology for aiding s...   \n",
            "\n",
            "                              Venue/journal/conference  Year  \\\n",
            "0                      NeurIPS Datasets and Benchmarks  2021   \n",
            "1                    Lecture Notes in Computer Science  2018   \n",
            "2    Annual International ACM SIGIR Conference on R...  2021   \n",
            "3    North American Chapter of the Association for ...  2021   \n",
            "4                                                ArXiv  2021   \n",
            "..                                                 ...   ...   \n",
            "995                      Int. J. Rough Sets Data Anal.  2018   \n",
            "996    Journal of Intelligence and Information Systems  2018   \n",
            "997                Information Processing & Management  2018   \n",
            "998      International Symposium on Information Theory  2018   \n",
            "999  Soft Computing - A Fusion of Foundations, Meth...  2018   \n",
            "\n",
            "                                               Authors  \\\n",
            "0    [{'authorId': '47583894', 'name': 'Nandan Thak...   \n",
            "1    [{'authorId': '32293755', 'name': 'A. Dekhtyar'}]   \n",
            "2    [{'authorId': '145580839', 'name': 'Jimmy J. L...   \n",
            "3    [{'authorId': '49715441', 'name': 'Luyu Gao'},...   \n",
            "4    [{'authorId': '1630412772', 'name': 'Thibault ...   \n",
            "..                                                 ...   \n",
            "995  [{'authorId': '12588093', 'name': 'Nidhika Yad...   \n",
            "996  [{'authorId': '40522433', 'name': 'Jan Kralj'}...   \n",
            "997  [{'authorId': '1404553249', 'name': 'Tony Russ...   \n",
            "998  [{'authorId': '2117890097', 'name': 'Su Li'}, ...   \n",
            "999  [{'authorId': '2060680819', 'name': 'Samuel Ma...   \n",
            "\n",
            "                                              Abstract  \n",
            "0    Existing neural information retrieval (IR) mod...  \n",
            "1                                                 None  \n",
            "2    Pyserini is a Python toolkit for reproducible ...  \n",
            "3    Classical information retrieval systems such a...  \n",
            "4    In neural Information Retrieval (IR), ongoing ...  \n",
            "..                                                 ...  \n",
            "995  Information retrieval is widely used due to ex...  \n",
            "996                                               None  \n",
            "997                                               None  \n",
            "998  In the problem of private information retrieva...  \n",
            "999                                               None  \n",
            "\n",
            "[1000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SqZIo2_S1ER"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MUqqj7hS1ES",
        "outputId": "d5a655c7-8750-415e-e218-9317a2c3ff3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           User_name         Posted_time  \\\n",
            "0        Naritasan41 2023-02-10 03:45:01   \n",
            "1          GuzuelaXd 2023-02-10 03:45:01   \n",
            "2          Molosse22 2023-02-10 03:45:01   \n",
            "3    aDhUhue3tRn6pxr 2023-02-10 03:45:01   \n",
            "4       IdealistStar 2023-02-10 03:45:01   \n",
            "..               ...                 ...   \n",
            "995     dj_ir0ngruve 2023-02-10 03:39:51   \n",
            "996       PBBenjamin 2023-02-10 03:39:50   \n",
            "997   SaraBerniecrat 2023-02-10 03:39:50   \n",
            "998         chav4197 2023-02-10 03:39:49   \n",
            "999    xiola_azuthra 2023-02-10 03:39:49   \n",
            "\n",
            "                                                  Text  \n",
            "0    RT @miraomiramira8: COVID-19のmRNAワクチンについて\\n\\nこ...  \n",
            "1    RT @brendadelriom: Embarazadas expuestas a las...  \n",
            "2    RT @KanekoaTheGreat: FLASHBACK: YouTube censor...  \n",
            "3    RT @backtolife_2023: New data appears to show ...  \n",
            "4    RT @kuu331108: 【モデルナのCEOであるステファン・バ ンセルは、「来年は10...  \n",
            "..                                                 ...  \n",
            "995  RT @DelthiaRicks: CDC-recommended vaccinations...  \n",
            "996  @ericareport Vaxxed, never been sick with Covi...  \n",
            "997  Never Again is Now Global - Five-part Docuseri...  \n",
            "998  RT @Mippcivzla: 🗣️ ¡𝐓𝐎𝐌𝐀 𝐏𝐑𝐄𝐂𝐀𝐔𝐂𝐈𝐎́𝐍!✍️🇻🇪\\nVen...  \n",
            "999  RT @AstroKatie: Avoiding covid has become one ...  \n",
            "\n",
            "[1000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# Enter your Twitter API credentials\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "consumer_key = \"u7L1lnR7HN85dn1qnTFO1cegb\"\n",
        "consumer_secret = \"QN1JrEmit2To46ZcwWAT4aI5QGWZXWRDDUPnMCWV5M66SFc8wT\"\n",
        "access_token = \"1144377060036620294-BSEicX3zH7hIhksbNZV9mrWFwa07cO\"\n",
        "access_token_secret = \"gxWMOodDq1nQAjix9mHEOUSAtgE7XH5ctHInm0XRslJce\"\n",
        "\n",
        "\n",
        "# Authenticate to Twitter\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "# Create API object\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Define the hashtag you want to search for\n",
        "hashtag = \"covid\"\n",
        "\n",
        "# Collect 1000 tweets containing the hashtag\n",
        "tweets = tweepy.Cursor(api.search, hashtag).items(1000)\n",
        "\n",
        "# Store the collected data in a list of dictionaries\n",
        "data = []\n",
        "for tweet in tweets:\n",
        "    data.append({\n",
        "        \"User_name\": tweet.user.screen_name,\n",
        "        \"Posted_time\": tweet.created_at,\n",
        "        \"Text\": tweet.text\n",
        "    })\n",
        "\n",
        "# Print the collected data\n",
        "\"\"\"for tweet in data:\n",
        "    print(\"User_name:\", tweet[\"User_name\"])\n",
        "    print(\"Posted_time:\", tweet[\"Posted_time\"])\n",
        "    print(\"Text:\", tweet[\"Text\"])\n",
        "    print(\"\\n\")\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "\"\"\"\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}